{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dJ3zkVSYMWM",
        "outputId": "7d7bb430-87ff-4106-e594-146412b974e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                                               title  \\\n",
            "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
            "1  Trump drops Steve Bannon from National Securit...   \n",
            "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
            "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
            "4  Donald Trump heads for Scotland to reopen a go...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
            "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
            "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
            "3  On Monday, Donald Trump once again embarrassed...          News   \n",
            "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
            "\n",
            "                  date  label  \n",
            "0    February 13, 2017      1  \n",
            "1       April 5, 2017       0  \n",
            "2  September 27, 2017       0  \n",
            "3         May 22, 2017      1  \n",
            "4       June 24, 2016       0  \n",
            "\n",
            "Dataset shape: (44898, 5)\n",
            "\n",
            "Label counts:\n",
            " label\n",
            "1    23481\n",
            "0    21417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your dataset folder in Google Drive\n",
        "path = '/content/drive/MyDrive/FakeNews_System/'\n",
        "\n",
        "# Load datasets\n",
        "df_fake = pd.read_csv(path + 'Fake.csv')\n",
        "df_real = pd.read_csv(path + 'True.csv')\n",
        "\n",
        "# Add labels (1 = fake, 0 = real)\n",
        "df_fake['label'] = 1\n",
        "df_real['label'] = 0\n",
        "\n",
        "# Combine and shuffle\n",
        "df = pd.concat([df_fake, df_real], ignore_index=True)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Preview\n",
        "print(df.head())\n",
        "print(\"\\nDataset shape:\", df.shape)\n",
        "print(\"\\nLabel counts:\\n\", df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Combine title and text into one column for processing\n",
        "df['content'] = df['title'] + \" \" + df['text']\n",
        "\n",
        "# Remove null values\n",
        "df.dropna(subset=['content'], inplace=True)\n",
        "\n",
        "# Get English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean text (without lemmatization)\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])  # remove punctuation\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # remove non-ASCII chars\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words and len(word) > 2]  # remove stopwords & short words\n",
        "    text = \" \".join(words)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # normalize spaces\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "df['content_clean'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Preview cleaned data\n",
        "print(df[['content', 'content_clean']].head())\n",
        "print(\"\\nShape after cleaning:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFvM8NA6chga",
        "outputId": "d732c544-9b2f-4575-f72d-4c932dcd2bfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  \\\n",
            "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
            "1  Trump drops Steve Bannon from National Securit...   \n",
            "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
            "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
            "4  Donald Trump heads for Scotland to reopen a go...   \n",
            "\n",
            "                                       content_clean  \n",
            "0  ben stein calls circuit court committed coup d...  \n",
            "1  trump drops steve bannon national security cou...  \n",
            "2  puerto rico expects lift jones act shipping re...  \n",
            "3  oops trump accidentally confirmed leaked israe...  \n",
            "4  donald trump heads scotland reopen golf resort...  \n",
            "\n",
            "Shape after cleaning: (44898, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize text\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Apply lemmatization on the cleaned content\n",
        "df['content_lemmatized'] = df['content_clean'].apply(lemmatize_text)\n",
        "\n",
        "# Preview\n",
        "print(df[['content_clean', 'content_lemmatized']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY9B7kBXdoUi",
        "outputId": "55cbe746-679a-4e5a-9300-c6cc5f7cd582"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       content_clean  \\\n",
            "0  ben stein calls circuit court committed coup d...   \n",
            "1  trump drops steve bannon national security cou...   \n",
            "2  puerto rico expects lift jones act shipping re...   \n",
            "3  oops trump accidentally confirmed leaked israe...   \n",
            "4  donald trump heads scotland reopen golf resort...   \n",
            "\n",
            "                                  content_lemmatized  \n",
            "0  ben stein call circuit court committed coup dt...  \n",
            "1  trump drop steve bannon national security coun...  \n",
            "2  puerto rico expects lift jones act shipping re...  \n",
            "3  oops trump accidentally confirmed leaked israe...  \n",
            "4  donald trump head scotland reopen golf resort ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Features: lemmatized text\n",
        "X = df['content_lemmatized']\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "# max_features limits the vocabulary size for efficiency\n",
        "# ngram_range=(1,2) considers unigrams and bigrams\n",
        "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
        "\n",
        "# Fit on the text and transform\n",
        "X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "# Preview shape\n",
        "print(\"TF-IDF feature matrix shape:\", X_tfidf.shape)\n",
        "\n",
        "# Check feature names\n",
        "print(\"Sample features:\", vectorizer.get_feature_names_out()[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSmMt8jueQn3",
        "outputId": "bda99c5c-38b0-4a0f-fe54-6a6b1f85c940"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF feature matrix shape: (44898, 10000)\n",
            "Sample features: ['aaron' 'abadi' 'abandon' 'abandoned' 'abandoning' 'abbas' 'abbott' 'abc'\n",
            " 'abc news' 'abc week' 'abdel' 'abdullah' 'abe' 'abedin' 'abide' 'ability'\n",
            " 'able' 'able get' 'aboard' 'abortion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Labels\n",
        "y = df['label']\n",
        "\n",
        "# Train-test split (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_lr = lr_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "5SjTDp1nelbR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Train LinearSVC (faster for high-dimensional text)\n",
        "svm_model = LinearSVC(max_iter=5000, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_svm = svm_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "UCedVHSde7Vr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "print(\"=== Logistic Regression Results ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"\\n=== SVM Results ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smu8cevve83E",
        "outputId": "c5e4b536-9540-47aa-9152-f9c0402b2a5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression Results ===\n",
            "Accuracy: 0.9899777282850779\n",
            "F1 Score: 0.9903866695150609\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      4284\n",
            "           1       0.99      0.99      0.99      4696\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "\n",
            "=== SVM Results ===\n",
            "Accuracy: 0.9963251670378619\n",
            "F1 Score: 0.9964844998402045\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4284\n",
            "           1       1.00      1.00      1.00      4696\n",
            "\n",
            "    accuracy                           1.00      8980\n",
            "   macro avg       1.00      1.00      1.00      8980\n",
            "weighted avg       1.00      1.00      1.00      8980\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Logistic Regression\n",
        "precision_lr = precision_score(y_test, y_pred_lr)\n",
        "recall_lr = recall_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "# SVM (LinearSVC)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Print results\n",
        "print(\"=== Logistic Regression ===\")\n",
        "print(f\"Precision: {precision_lr:.4f}, Recall: {recall_lr:.4f}, F1: {f1_lr:.4f}\")\n",
        "\n",
        "print(\"\\n=== SVM (LinearSVC) ===\")\n",
        "print(f\"Precision: {precision_svm:.4f}, Recall: {recall_svm:.4f}, F1: {f1_svm:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLRU-BPJiZVt",
        "outputId": "d5b219a4-8652-445d-81f5-63d02428fd45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression ===\n",
            "Precision: 0.9936, Recall: 0.9872, F1: 0.9904\n",
            "\n",
            "=== SVM (LinearSVC) ===\n",
            "Precision: 0.9970, Recall: 0.9960, F1: 0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Logistic Regression\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "# SVM\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Print overall results\n",
        "print(\"=== Overall Model Performance ===\")\n",
        "print(f\"Logistic Regression -> Accuracy: {accuracy_lr:.4f}, F1 Score: {f1_lr:.4f}\")\n",
        "print(f\"SVM (LinearSVC)    -> Accuracy: {accuracy_svm:.4f}, F1 Score: {f1_svm:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0tOIEaVhiV3",
        "outputId": "9ac76426-198a-4035-8d0c-34511dedbf6a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Overall Model Performance ===\n",
            "Logistic Regression -> Accuracy: 0.9900, F1 Score: 0.9904\n",
            "SVM (LinearSVC)    -> Accuracy: 0.9963, F1 Score: 0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Folder in your Google Drive to save models\n",
        "save_path = '/content/drive/MyDrive/FakeNews_System/'\n",
        "\n",
        "# --- Save Logistic Regression model ---\n",
        "with open(save_path + 'lr_model.pkl', 'wb') as f:\n",
        "    pickle.dump(lr_model, f)\n",
        "\n",
        "# --- Save SVM model ---\n",
        "with open(save_path + 'svm_model.pkl', 'wb') as f:\n",
        "    pickle.dump(svm_model, f)\n",
        "\n",
        "# --- Save TF-IDF vectorizer ---\n",
        "with open(save_path + 'vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "print(\"Models and vectorizer saved successfully in Drive!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-I3ERYkiwPo",
        "outputId": "e1de4717-0cfa-4438-8efe-7ff7ca3d2792"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models and vectorizer saved successfully in Drive!\n"
          ]
        }
      ]
    }
  ]
}